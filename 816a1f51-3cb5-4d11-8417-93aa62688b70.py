#!/usr/bin/env python
# coding: utf-8

# <div class="alert alert-info">
# 
# <h6>Комментарий студента</h6>
#     
# Приветствую на моем проекте) Меня зовут Дима. Жду обратной связи)

# <div style="border:solid lightseagreen 3px; padding: 20px">
# <div>    
# <p><font color="black" >
# Привет, Дима! Меня зовут Мария Четырева, и я буду делать ревью твоего проекта. Давай будем общаться на «ты». 
# По ходу твоего решения я буду оставлять комментарии, обрати внимание на их цвет.</font></p>
# </div>
# 
# <div class="alert alert-success">
# 
# <b>✔️</b> Зеленым цветом отмечены удачные и элегантные решения, на которые можно опираться в будущем.
# 
# </div>
# 
# <div class="alert alert-warning">
# 
# <b>⚠️</b> Жёлтым цветом выделено то, что в следующий раз можно сделать по-другому. Это не критичные ошибки, исправление которых остается на твое усмотрение. Однако постарайся, чтобы после твоих доработок их было не больше 3.
# 
# </div>
# 
# <div class="alert alert-danger">
# 
# <b>❌</b> Красным цветом отмечены критичные ошибки, без исправления которых проект не будет принят.
# 
# </div>
# 
# <p>Давай работать над проектом в диалоге: если ты что-то меняешь в проекте по моим рекомендациям — пиши об этом. Выбери для своих комментариев какой-то заметный цвет, так мне будет легче отследить изменения, например вот так:
# 
# <div class="alert alert-info">
# <b>Комментарий студента:</b> Ок
# <br>
# </div>
#     
# Пожалуйста, не перемещай, не изменяй и не удаляй мои комментарии. Всё это поможет выполнить повторную проверку твоего проекта оперативнее. </p>
# 
# </div>

# <div style="border:solid lightseagreen 3px; padding: 20px">
# <div>
# <b>Общий комментарий ревьюера: </b>
#    
#    Замечательная работа! Ты правильно умеешь интерпретировать полученные результаты и формулировать выводы. Уверенно пользуешься pandas, умеешь строить воронку событий и понимаешь основы A/B тестирования. Ошибок нет, но отправляю работу, чтобы ты мог ознакомиться с комментариями и задать интересующие вопросы,если они есть. Если все ок, то присылай работу еще раз и я ее приму.
# 
# </div>
#     

# <div class="alert alert-info">
# 
# <h6>Комментарий студента</h6>
#     
# Привет, Маша! Спасибо за проверку и обратную связь) вопросов вроде как нет) 

# 
# <img src="https://i.ibb.co/vZtG5zL/image.jpg" width=450 height=450 />

# # Анализ поведения пользователей мобильного приложения по продаже продуктов питания

# # Описания
# 
# В стартапе, который продаёт продукты питания нужно разобраться, как ведут себя пользователи мобильного приложения. Также был запущен А/А/В - тест. Дизайнеры захотели поменять шрифты во всём приложении, а менеджеры усомнились, что пользователям будет удобно. Договорились принять решение по результатам A/A/B-теста. Пользователей разбили на 3 группы: 2 контрольные со старыми шрифтами и одну экспериментальную — с новыми. <br/>
# 
# **Данные для проекта** предоставлены в одном датафрейме с логами *logs_exp.csv*.<br/>
# 
# **Задачи проекта:**
# - изучить воронку событий;
# - узнать как пользователи доходят до покупки;
# - выяснить сколько пользователей доходит до покупки, а сколько — «застревает» на предыдущих шагах и на каких именно;
# - проанализировать результаты А/А/В - теста;
# - выяснить какой шрифт лучше по результатам А/А/В- теста.
# 
# 
# **Цель проекта** проанализировать воронку продаж с помощью событийного анализа и выявить целесообразность проведенного A/B - теста. 

# ## Загрузка данных и знакомство с данными

# In[1]:


import pandas as pd
import numpy as np
from scipy import stats as st
from statsmodels.stats.proportion import proportions_ztest
import plotly.express as px
import plotly.graph_objects as go
import matplotlib.pyplot as plt
import math as mth


# In[2]:


pd.options.display.max_colwidth = -1
df = pd.read_csv('/datasets/logs_exp.csv', sep = '\t')
df.info()
df


# In[3]:


df['EventName'].unique()


# ### Вывод
# 
# В предоставленном датафрейме **4 столбца и 244126 наблюдений**.<br/>
# 
# Столбцы содержат следующую информацию:
# - *EventName* — название события;
# - *DeviceIDHash* — уникальный идентификатор пользователя;
# - *EventTimestamp* — время события;
# - *ExpId* — номер эксперимента: 246 и 247 — контрольные группы, а 248 — экспериментальная.
# 
# Преждем чем приступать к решению поставленных задач, необходимо провести предобработку данных:
#  - наименования столбцов привести к нижнему регистру и изменить имена для удобного дальнейшего использования;
#  - столбец *EventTimestamp* привести к соответствующему типу данных;
#  - добавить столбец с датой;
#  - проверить лог на дубликаты.
#  
# Данные в столбце *EventName* приводить к нижнему регистру не буду, т.к. в нем представлено всего 5 уникальных названий событий и при переводе в нижний регистр названия станут нечитабельны.<br/>
# Пропусков необнаружено.

# <div class="alert alert-success">
# 
# <b>✔️ Комментарий ревьюера:</b> Отлично, с данными ознакомились
# 
# </div>

# ## Предобработка данных.

# In[4]:


df.columns = ['event_name', 'device_id', 'event_time', 'exp_id']
df['event_time'] = pd.to_datetime(df['event_time'], unit = 's')
df['date'] = df['event_time'].dt.date
df.head()


# <div class="alert alert-success">
# 
# <b>✔️ Комментарий ревьюера:</b> Да, с такими названиями будет удобнее работать. 
# 
# </div>

# In[5]:


print('Количество дубликатов:', df.duplicated().sum())


# In[6]:


df = df.drop_duplicates()
print('Размер датафрейма после удаления дубликатов:', df.shape[0], 'строк')


# <div class="alert alert-success">
# 
# <b>✔️ Комментарий ревьюера:</b> Молодец, что не забыл про дубли. 
# 
# </div>

# ### Результат предобработки
# 
# В ходе предобработки были внесены следующие изменения:
# - наименования столбцов были изменены с *EventName, DeviceIDHash, EventTimestamp, ExpId* на *event_name, device_id, event_time, exp_id*, соответственно;
# - столбец *event_time* переведен в соответствующий тип данных;
# - добавлен столбец с датой события;
# - выявлены **413 дублирующих наблюдений**, которые были удалены;
# - после удаления дубликатов, в дф стало **243713** строки, т.е. **уменьшился менее чем на 1 %**, что некритично. 

# <div class="alert alert-warning">
# <b>⚠️ Комментарий ревьюера:</b> На данном этапе неплохо было бы проверить, что у нас нет таких пользователей, которые попали в несколько групп сразу
# </div>

# ## Изучение данных

# ### Количество событий, пользователей и среднее количество событий на пользователя.

# Для определения статистики, которую можно считать средней мерой, посмотрим на гистограмму количества событий по уникальным пользователям

# In[7]:


(df.groupby('device_id').agg({'event_name':'count'})).hist(bins = 100, figsize = (8, 5))
plt.title('Гистограмма распределения количества событий по уникальным пользователям')
plt.xlabel('Количество событий')
plt.ylabel('Частота событий');


# По гистограмме видно, что распределение совсем не похоже на нормальное, поэтому в качестве статистики, описывающую среднюю меру на данном этапе лучше взять медиану.

# In[8]:


print(
    ' Количество событий:'
    , df['event_name'].count(),'\n'
    , 'Количество уникальных пользователей:'
    , df['device_id'].nunique(),'\n'
    , 'Среднее количество событий на пользователя:'
    , ((df.groupby('device_id').agg({'event_name':'count'})).event_name.median()).astype('int')  
)


# <div class="alert alert-success">
# 
# <b>✔️ Комментарий ревьюера:</b> Все верно
# 
# </div>

# #### Вывод
# В качестве статистики, описывающей среднее количество событий на одного уникального посетителя было взято медианное значение. Но 20 событий на одного пользователя, возможно, тоже много, и здесь подойдет значение по моде, но это можно точно выяснить, изучив воронку событий.

# ### Временной интервал в логе

# In[9]:


print(' Данные предоставлены за период'
      , df['date'].max() - df['date'].min()
      ,'\n'
      , 'Дата начала:'
      , df['event_time'].min()
      ,'\n'
      , 'Дата окончания:'
      , df['event_time'].max() 
)


# In[10]:


fig = px.histogram(
    df
    , x = 'event_time'
    , title = 'Гистограмма распределения количества логов по времени'
)
fig.update_layout(
    yaxis_title = 'Количество логов'
    , xaxis_title = 'Дата'
)
fig.update_xaxes(nticks = 20)
fig.show()


# На гистограмме отчетливо видны **полные данные и пиковые значения** в сутках начиная **с 01.08 и до 07.08**. Все события **до 01.08** можно отбросить, т.к. **события** в них **незначительные.**

# <div class="alert alert-success">
# 
# <b>✔️ Комментарий ревьюера:</b> На самом деле, можно заметить, что у нас есть данные до 9 часов вечера 2019-08-07. Так что чтобы взять прям полные дни, нужно захватить и последние 3 часа 31 июля. Но твой вариант тоже считается корректным 
# 
# </div>
# 

# In[11]:


# корректировка временного интервала
df['date'] = pd.to_datetime(df['date'])
df_new = df[df['date'].isin(pd.date_range('2019-08-01', '2019-08-07'))]

print('После корректировки временного интервала датафрейм уменьшился на:'
     ,  round(100 - (df_new.shape[0] / df.shape[0] * 100),2)
     , '%'
)
print()
df_new.info()


# ##### Изменения корректировки временного интервала.

# In[12]:



print(
    ' Количество событий:'
    , '\n до изменений:', df['event_name'].count()
    , '\n после изменений:',  df_new['event_name'].count()
    , '\n количество событий уменьшилось на:'
    , df['event_name'].count() - df_new['event_name'].count()
    , 'или на {:.2%}'.format(1 - df_new['event_name'].count() / df['event_name'].count())
)
print()
print(
    ' Количество уникальных пользователей:'
    , '\n до изменений:', df['device_id'].nunique()
    , '\n после изменений:',  df_new['device_id'].nunique()
    , '\n количество уникальных пользователей уменьшилось на:'
    , df['device_id'].nunique() - df_new['device_id'].nunique()
    , 'или на {:.2%}'.format(1 - df_new['device_id'].nunique() / df['device_id'].nunique())
)    
    
print()
# введу переменную для медианы, чтоб не писать огромный код
median_df = (
        (df.groupby('device_id')
         .agg({'event_name':'count'}))
        .event_name.median()
        ).astype('int')
median_df_new = (
        (df_new.groupby('device_id')
         .agg({'event_name':'count'}))
        .event_name.median()
        ).astype('int')
        
print(
    ' Среднее количество событий на пользователя:'
    , '\n до изменений:', median_df
    , '\n после изменений:',  median_df_new
    , '\n среднее количество событий на пользователя изменилось на:'
    , median_df - median_df_new
)
print()
print('Количество экспериментальных групп после корректировки:', df_new['exp_id'].nunique())


# #### Вывод.
# По гистограмме был определен **временной интервал с 01.08 по 07.08**. **Данные**, которые имелись на даты **с 25.07 по 31.07** ничего из себя не представляют, по сравнению с выбранным периодом. Возможно приложение тогда только было запущено или находилось на тестировании. В любом случае **эти данные были удалены**.<br/>
# **После корректировки** временного интервала **лог уменьшился на 1,16 %**, как и количество событий, а уникальных **пользователей стало меньше всего на 0,23%**. Также уменьшилась медиана на 1.<br/>
# Как видно из приведенных чисел - потеря данных совсем маленькая, да и оставлять "странные" данные тоже некорректно.

# <div class="alert alert-success">
# 
# <b>✔️ Комментарий ревьюера:</b> Да, потери незначительны
# 
# </div>

# ## Воронка событий

# ### Количество событий

# In[13]:


events =(
    df_new.groupby('event_name')
    .agg({'event_name':'count'})
    .rename(columns = {'event_name':'count'})
    .sort_values(by = 'count', ascending = False)
    .reset_index()
)

fig = px.bar(
    events
    , x = 'event_name'
    , y  = 'count'
    , title = 'Количество событий'
    , labels = dict(
    event_name = 'Событие'
    , count = 'Количество')
)
fig.show()
events


# <div class="alert alert-success">
# 
# <b>✔️ Комментарий ревьюера:</b> Наглядно и понятно, класс
# 
# </div>

# #### Вывод
# События в порядке убывания распределяются так:
# 
# 1) просмотр главной страницы;<br/>
# 2) просмотр экрана с продуктами;<br/>
# 3) просмотр корзины;<br/>
# 4) страница оплаты/подтверждения оплаты;<br/>
# 5) страница с руководство (инструкцией).<br/>
# 
# При рассмотрении графика можно выделить 3 наблюдения:
# - просмотр главной страницы происходит более в два раза чаще, чем просмотр экрана с продуктами;
# - между количеством событий: просмотр экрана с продуктами, просмотр корзины, страница подтверждения оплаты, - разница не такая большая, как с просмотром главной страницы;
# - страницу с руководством просматривается очень редко.
# 
# 
# 
# 

# ### Количество пользователей по каждому событию

# In[14]:


user_events = (
    df_new.groupby('event_name')
    .agg({'event_name':'count', 'device_id':'nunique'})
    .rename(columns = {'event_name':'count', 'device_id':'n_users'})
    .sort_values(by = 'count', ascending = False)
    .reset_index()
)
user_events['part'] = round((user_events['n_users'] / df_new['device_id'].nunique() * 100),2)

fig = px.bar(
    user_events
    , x = 'event_name'
    , y  = 'part'
    , title = 'Доля пользователей по событиям'
    , labels = dict(
    event_name = 'Событие'
    , part = 'Доля, в %')
)
fig.show()

user_events


# #### Вывод/Предположительный порядок событий
# График нам показывает, следующую картину:
# - **98,5 %** пользователей посещают главную страницу;
# - **61 %** пользователей продолжают пользоваться приложением, переходя на страницу с продуктами;
# - **50 %** пользователей переходят в корзину с выбранными продуктами;
# - **47 %** оплачивают свои заказы;
# - **11,5 %** просматривают руководство.
# 
# Из этого можно уверенно сказать, что если пользователь зашел на страницу с выбором продуктов, то в **94 %** случаев он оплатит заказ, что показывает вполне хорошую конверсию. А вот после просмотра главной страницы только **62 %** пользователей переходят к просмотру товаров.<br/>
# Страница с просмотром руководства популярностью не пользуется - ее практически всегда скипают. Неплохо было бы разобраться в причинах - возможно у людей нет времени на это, или страница не очень удобна, или же наше приложение интутивно понятное и к нему не требуется такая страница.<br/>
# 
# В итоге предположительный порядок событий следующий:<br/>
# 1) Просмотр главной страницы - т.к. у нас мобильное приложение, то, как правило, открывается сразу главная страница; конечно есть возможность открыть приложение через push-уведомление типа "Ваши покупки ждут Вас в корзине, перейдите в нее для оформления заказа" - в таком случае пользователь сразу попадет в корзину с выбранными заказами, но такое может быть не часто, тем более, что многие просто отключат уведомления от приложений;<br/>
# 2) Просмотр страницы с продуктами - событие, на котором пользователь ищет необходимый товар (невыбрав товар и не переместив его в корзину можно его оплатить только в случае кнопки "купить товар сразу" - сейчас мы не знаем есть ли такая фича у приложения);<br/>
# 3) Просмотр корзины - страница, где пользователь корректирует свой заказ, выбирает количество, выбирает опции доставки и оформляет заказ;<br/>
# 4) страница с оплатой заказа - пользователь выбирает тип оплаты и видит либо подтверждение заказа или, в случае, оплаты онлайн видит подтверждение оплаты и заказа.<br/>
# 
# Просмотр руководства не вписывается в логичный порядок действий пользователя - очень многие пропускают этот шаг. Подобные страницы как правило появляются при первом запуске приложения и многие его скипают или же на этот этап можно перейти с люого шага и пользователи этого не делают из-за интуитивно понятного интерфеса приложения.

# <div class="alert alert-success">
# 
# <b>✔️ Комментарий ревьюера:</b> Совершенно верно! Этап Tutorial лишний в цепочке событий, поэтому при расчете воронки его учитывать не будем. Доступ к туториалу действительно есть с каждого шага, да и в принципе, люди редко читают инструкции
# </div>
# 

# In[15]:


user_events = user_events[user_events['event_name'] != 'Tutorial']
user_events


# ### Анализ воронки событий

# In[16]:


# построение воронки
fig = go.Figure(
    go.Funnel(
        y = user_events['event_name']
        , x = user_events['n_users']
        , textposition = 'inside'
        , textinfo = 'value + percent previous + percent initial'
    )
)

fig.update_layout(
                title = {
                    'text': 'Воронка событий'
                    , 'y': 0.95
                    , 'x': 0.55
                    }
)
fig.show()
print(' initial - начальный процент'
     ,'\n previous - предыдущий процент')


# #### Вывод
# 
# - **от просмотра главной страницы до просмотра каталога товаров теряется 38 % пользователей**;
# - **50 % от первого шага и 81 % со второго шага переходят к оформлению заказа**;
# - **от просмотра главной страницы до оплаты доходит 48 % пользователей, а из тех, кто просматривал корзину к оплате переходят 95 %;**
# 
# С одной стороны неприятно, что меньше 50 % пользователей, которые открыли приложение оплатили свои заказы, с другой стороны приятно видеть, что 95 % пользователей, которые переместили товары в корзину оплачивают свой заказ

# <div class="alert alert-success">
# 
# <b>✔️ Комментарий ревьюера:</b> Действительно, заметный провал на первом шаге. Вероятно, нужно лучше прорабатывать механику, чтобы пользователи переходили к OffersScreen.
# 
# </div>

# ## Изучение результатов эксперимента

# ### Подготовка данных для статистического теста

# In[17]:


# сводная таблица для сбора всех необходимых данных для дальшейшего теста
users_and_events = df_new.pivot_table(
    index = 'exp_id'
    , columns = 'event_name'
    , values = 'device_id'
    , aggfunc = 'nunique'
).reset_index()
users_and_events


# In[18]:


# добавление столбца с количеством пользователей по каждой группе
users_and_events['n_users'] = (
    users_and_events['exp_id']
    .apply(
        lambda x: (
            df_new.groupby('exp_id')
            .agg({'device_id':'nunique'})
        ).loc[x])
)
users_and_events = users_and_events.set_index('exp_id')
users_and_events


# In[19]:


# объединение двух контрольных групп теста в одну
row = users_and_events.loc[246] + users_and_events.loc[247]
row.name = '246_247'
users_and_events = users_and_events.append([row])
# изменение порядка столбцов согласно воронке событий
users_and_events = users_and_events[
    [
        'MainScreenAppear'
    , 'OffersScreenAppear'
    , 'CartScreenAppear'
    , 'PaymentScreenSuccessful'
    , 'Tutorial'
    , 'n_users'
    ]
]
users_and_events = users_and_events.reindex([246, 247, '246_247', 248])
users_and_events


# В одном ДФ собраны количество уникальных пользователей по каждому событию разбитое на группы, общее количество пользователей в каждой группе. Две контрольные группы объединены в одну для увеличения мощности теста, плюс в дальнейшем не придется делать поправку на множественное тестирование.

# ### Сравнение двух контрольных групп через z-тест
# 
# Уровень статистической значимости **alpha = 0.05**<br/>
# Нулевая гипотеза **Н0 - доли пользователей в контрольных группах 246 и 247 одинаковы для всех событий**<br/>
# Альтернативная гипотеза **Н1 - доли пользователей в котрольных группах 246 и 247 различаются для всех событий**

# <div class="alert alert-success">
# 
# <b>✔️ Комментарий ревьюера:</b> Гипотезы сформулированы корректно, молодец!
# 
# </div>

# In[20]:


# ДФ с результатами z-теста для контрольных групп
control_groups_pivot = pd.DataFrame(
    columns = [
        'Группа_1'
        , 'Группа_2'
        , 'Событие'
        , 'alpha'
        , 'p_value'
        , 'Результат'
    ]
)

result_text = [
    'Отвергаем нулевую гипотезу - различия между долями статистически значимы'
    , 'Не удалось отвергнуть нулевую гипотезу - различия между долями статистически незначимы'
]

group_1 = 246
group_2 = 247
current_row = users_and_events.loc[group_1]
alpha = 0.05
for event_number in range(4):
    current_event = users_and_events.columns[event_number]
    result = proportions_ztest(
                              (current_row[current_event]
                               , users_and_events[current_event][group_2])
                              , (current_row['n_users']
                               , users_and_events['n_users'][group_2])
                              )[1]
    new_row = {
              'Группа_1': group_1
              , 'Группа_2': group_2
              , 'Событие': users_and_events.columns[event_number]
              , 'alpha': alpha
              , 'p_value': round(result,2)
              , 'Результат': result_text[result > alpha]
}
    control_groups_pivot = control_groups_pivot.append([new_row])
control_groups_pivot.index = range(len(control_groups_pivot))
control_groups_pivot


# #### Вывод.
# **В результате проверки долей** z-тестом **статистически значимых различий не выявлено**. **Нулевую гипотезу (Н0)** - доли пользователей в контрольных группах 246 и 247 одинаковы для всех событий, **отвергнуть не удалось**. Следовательно **А/А тест проведен корректно**.

# ### Сравнение котрольных групп с экспериметальной
# 
# **Для контрольной группы - 246 и экспериментальной - 248**<br/>
# Уровень статистической значимости **alpha = 0.05**<br/>
# Нулевая гипотеза **Н0 - доли пользователей в группах 246 и 248 одинаковы для всех событий**<br/>
# Альтернативная гипотеза **Н1 - доли пользователей в группах 246 и 248 различаются для всех событий**<br/>
# 
# **Для контрольной группы - 247 и экспериментальной - 248**<br/>
# Уровень статистической значимости **alpha = 0.05**<br/>
# Нулевая гипотеза **Н0 - доли пользователей в группах 247 и 248 одинаковы для всех событий**<br/>
# Альтернативная гипотеза **Н1 - доли пользователей в группах 247 и 248 различаются для всех событий**<br/>
# 
# **Для двух контрольных групп - 246_247 экспериментальной - 248**<br/>
# Уровень статистической значимости **alpha = 0.05**<br/>
# Нулевая гипотеза **Н0 - доли пользователей в группах 246_247 и 248 одинаковы для всех событий**<br/>
# Альтернативная гипотеза **Н1 - доли пользователей в группах 246_247 и 248 различаются для всех событий**<br/>

# In[21]:


# ДФ с результатами z-теста для всех групп
AB_table = pd.DataFrame(
    columns = [
        'Группа_1'
        , 'Группа_2'
        , 'Событие'
        , 'alpha'
        , 'p_value'
        , 'Результат'
    ]
)

result_text = [
    'Отвергаем нулевую гипотезу - различия между долями статистически значимы'
    , 'Не удалось отвергнуть нулевую гипотезу - различия между долями статистически незначимы'
]

for i in range(3):
    group_1 = users_and_events.index[i]
    current_row = users_and_events.loc[group_1]
    group_2 = 248
    for event_number in range(4):
        current_event = users_and_events.columns[event_number]
        result = proportions_ztest(
                              (current_row[current_event]
                               , users_and_events[current_event][group_2])
                              , (current_row['n_users']
                               , users_and_events['n_users'][group_2])
                              )[1]
        new_row = {
              'Группа_1': group_1
              , 'Группа_2': group_2
              , 'Событие': users_and_events.columns[event_number]
              , 'alpha': alpha
              , 'p_value': round(result,2)
              , 'Результат': result_text[result > alpha]
}
        AB_table = AB_table.append([new_row])
    
AB_table.index = range(len(AB_table))
AB_table


# #### Вывод
# **В результате множественного теста** проверки долей **выявлено отсутствие статистически значимых различий между группами** - как попарно, так и в сравнение двух контрольных групп с экспериментальной. При проведении множественного теста для каждого последующего теста расте вероятность ошибки первого рода, но т.к. нулевые гипотезы отвергуть не удалось, то корректировать p_value для сравнения с уровнем статистической значимости не требуется.

# <div class="alert alert-success">
# 
# <b>✔️ Комментарий ревьюера:</b> И правда, хотя мы и наблюдаем уменьшение долей всех событий на пользователя, эти результаты далеки от статистической значимости
# </div>

# <div class="alert alert-success">
# 
# <b>✔️ Комментарий ревьюера:</b> Да, нам повезло, что получали во всех случаях достаточно большие p-value и даже с alpha=0.1 не можем отвергнуть нулевую гипотезу. А вообще, учитывая 12 проверок гипотез, уровень критической значимости следует уменьшить.
# </div>

# ## Общий вывод.
# **Поставленная цель проекта** - проанализировать воронку продаж с помощью событийного анализа и выявить целесообразность проведенного A/B - теста. <br/>
# **Данные для проекта**, были предоставлены в одном датафрейме с логами *logs_exp.csv*.<br/>
# 
# При работе над проектом была проведена предобработка данных, она коснулась:
# - наименования столбцов были изменены;
# - столбец *event_time* переведен в соответствующий тип данных;
# - добавлен столбец с датой события;
# - после удаления 413 дубликатов, в дф стало 243713 строки, т.е. уменьшился менее чем на 1 %, что некритично.
# 
# До корректировки временного интервала данные охватывали 13 дней, с 2019-07-25 04:43:36 по 2019-08-07 21:15:17.<br/>
# Для корректировки временного интервала были отброшены данные в период с 25.07 по 31.07 включительно. Датафрейм уменьшился на 1,16%.<br/>
# 
# При изучении событий была построена предположительня воронка:
# 1) Просмотр главной страницы;<br/>
# 2) Просмотр страницы с продуктами;<br/>
# 3) Просмотр корзины;<br/>
# 4) страница с оплатой заказа;<br/>
# Событие - просмотр руководства не вошел в воронку, т.к. оно невписывается в логичный порядок действий пользователя.<br/>
# 
# При анализе воронки выяснилось следующее:
# - от просмотра главной страницы до просмотра каталога товаров теряется 38 % пользователей;
# - 50 % от первого шага и 81 % со второго шага переходят к оформлению заказа;
# - от просмотра главной страницы до оплаты доходит 48 % пользователей, а из тех, кто просматривал корзину к оплате переходят 95 %.
# 
# Результаты анализа А/А/В:
# - в результате проверки долей двух контрольных групп z-тестом статистически значимых различий не выявлено не было;
# - в результате множественного теста проверки долей контрольных групп и экспериментальной (как попарно, так и двух контрольных групп с экспериментальной) статистически значимых различий также не было выявлено.
# 
# Исходя из всего вышеописанного можно сказать следующее:<br/>
# Результат теста можно признать неуспешным - изменение шрифта в приложении никак не повлияло на изменение долей по событиям. <br/>
# 
# Рекомендации:<br/>
# Если имеется список гипотез, то обратиться к нему, расчитать приоритетную гипотезу через фреймоворк ICE или RICE, провести A/B - тест, проанализировать результаты.
# 
# 
# 
# 
# 
# 
# 
# 
# 
# 

# <div class="alert alert-success">
# 
# <b>✔️ Комментарий ревьюера:</b> Отличный вывод! Правда, вряд ли можно назвать результаты неуспешными, главное — не стало хуже от применения новых шрифтов.
# </div>
